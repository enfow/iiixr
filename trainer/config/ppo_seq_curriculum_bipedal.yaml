# Training Configuration File - PPO Sequential Models
# Environment settings
env: "CurriculumBipedalWalker-v3"
result_name: "test"
model:
  model: "ppo_seq"  # Options: ppo, sac, rainbow_dqn, discrete_sac, td3, ppo_seq
  hidden_dim: 256
  n_layers: 2
  embedding_type: "transformer"  # Options: fc, lstm, transformer
  seq_len: 2
  seq_stride: 1  # When > 1: Use strided processing for both LSTM and Transformer
  use_layernorm: true
  n_fc_layers: 2

# Training parameters
seed: 42
episodes: 20000
lr: 3e-4
gamma: 0.99
batch_size: 256
n_envs: 8
curriculum_threshold: 100

# Device settings
device: "cpu"  # Options: cpu, cuda

# Evaluation settings
eval: true
eval_env: "BipedalWalkerHardcore-v3"
eval_period: 10
eval_episodes: 10

# Save settings
save_dir: "results"

# PPO specific parameters
ppo_epochs: 7
clip_eps: 0.2
n_transactions: 1000
normalize_advantages: true
gae: true
gae_lambda: 0.95
max_grad_norm: 0.5
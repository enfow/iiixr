# Training Configuration File for Testing
# Environment settings
env: "CartPole-v1"
model:
  model: "ppo"  # Options: ppo, sac, rainbow_dqn, discrete_sac, td3
  hidden_dim: 64
  n_layers: 2
  embedding_type: "fc"  # Options: fc, transformer

# Training parameters
seed: 42
episodes: 100
max_steps: 500
lr: 3e-4
gamma: 0.99
buffer_size: 10000
batch_size: 32
start_steps: 1000

# Device settings
device: "cpu"  # Options: cpu, cuda

# Evaluation settings
eval: true
eval_period: 5
eval_episodes: 5

# Save settings
save_dir: "results"

# PPO specific parameters
ppo_epochs: 4
clip_eps: 0.2
n_transactions: 100
normalize_advantages: false

# SAC specific parameters
tau: 0.005
entropy_coef: 0.2

# Rainbow DQN specific parameters
alpha: 0.6
beta_start: 0.4
beta_frames: 10000
target_update_interval: 1000
n_steps: 3
n_atoms: 51
v_min: -10.0
v_max: 10.0

# TD3 specific parameters
policy_delay: 2
policy_noise: 0.2
noise_clip: 0.5
exploration_noise: 0.1 